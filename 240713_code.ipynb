{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCVライブラリをインポート\n",
    "import tensorflow as tf  # TensorFlowライブラリをインポート\n",
    "from keras.utils import to_categorical  # ラベルをone-hotエンコードするための関数をインポート\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler, ReduceLROnPlateau  # 学習のコールバックをインポート\n",
    "import numpy as np  # 数値計算ライブラリをインポート\n",
    "from sklearn.model_selection import train_test_split  # データをトレーニングセットとテストセットに分割する関数をインポート\n",
    "from sklearn.preprocessing import MinMaxScaler  # データの正規化を行うための関数をインポート\n",
    "from PIL import Image  # 画像処理ライブラリをインポート\n",
    "import glob  # ファイルパスのパターンマッチングを行うためのライブラリをインポート\n",
    "import matplotlib.pyplot as plt  # データの可視化を行うライブラリをインポート\n",
    "import os  # OS操作を行うライブラリをインポート\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, roc_curve, f1_score  # モデル評価指標をインポート\n",
    "from keras.models import Sequential, Model  # Kerasのモデル作成に必要なクラスをインポート\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Conv2D, MaxPooling2D, Activation, BatchNormalization  # Kerasのレイヤーをインポート\n",
    "from keras import optimizers  # Kerasのオプティマイザをインポート\n",
    "from keras.preprocessing import image  # 画像データの前処理を行うための関数をインポート\n",
    "import random  # 乱数生成ライブラリをインポート\n",
    "import csv  # CSV操作ライブラリをインポート\n",
    "import scipy\n",
    "\n",
    "# DEBUGフラグを設定\n",
    "DEBUG = False\n",
    "\n",
    "# 画像を正方形にする関数\n",
    "def square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        result = pil_img\n",
    "        return result\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), (background_color))\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), (background_color))\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "\n",
    "# PIL画像をOpenCV画像に変換する関数\n",
    "def pil2opencv(in_image):\n",
    "    out_image = np.array(in_image, dtype=np.uint8)\n",
    "    return out_image\n",
    "\n",
    "# OpenCV画像をPIL画像に変換する関数\n",
    "def opencv2pil(in_image):\n",
    "    new_image = in_image.copy()\n",
    "    new_image = Image.fromarray(new_image)\n",
    "    return new_image\n",
    "\n",
    "# ハフ変換を用いて画像中の円を検出する関数\n",
    "def hough(img):\n",
    "    img_median = cv2.medianBlur(img, 15)\n",
    "    circles = cv2.HoughCircles(img_median, cv2.HOUGH_GRADIENT, 1.5, 100,\n",
    "                               param1=150, param2=100, minRadius=50, maxRadius=300)\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    img_edges_hough = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    for i in circles[0, :]:\n",
    "        cv2.circle(img_edges_hough, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "        cv2.circle(img_edges_hough, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
    "        HARD_LIMIT_DIM = 288\n",
    "        biggestCircle = [0, 0, 0]\n",
    "        for i in circles[0, :]:\n",
    "            z = i[2]\n",
    "            if (z > biggestCircle[2]) and (z < HARD_LIMIT_DIM):\n",
    "                biggestCircle = i\n",
    "        cv2.circle(img_edges_hough, (biggestCircle[0], biggestCircle[1]), biggestCircle[2], (255, 0, 0), 10)\n",
    "        cv2.circle(img_edges_hough, (biggestCircle[0], biggestCircle[1]), 2, (255, 0, 0), 10)\n",
    "        outerRad = int(biggestCircle[2])\n",
    "        shape = img_edges_hough.shape[1::-1]\n",
    "        outerCircle = np.zeros((shape[1], shape[0]), dtype=np.uint8)\n",
    "        cv2.circle(outerCircle, center=(biggestCircle[0], biggestCircle[1]), radius=outerRad, color=255, thickness=-1)\n",
    "        ori[outerCircle == 0] = [255]\n",
    "    return ori\n",
    "\n",
    "# グレースケール画像をRGB画像に変換する関数\n",
    "def gray_to_rgb(X):\n",
    "    X_transpose = np.array(X.transpose(0, 1, 2, 3))\n",
    "    ret = np.empty((X.shape[0], 288, 288, 3), dtype=np.float32)\n",
    "    ret[:, :, :, 0] = X_transpose[:, :, :, 0]\n",
    "    ret[:, :, :, 1] = X_transpose[:, :, :, 0]\n",
    "    ret[:, :, :, 2] = X_transpose[:, :, :, 0]\n",
    "    return ret.transpose(0, 1, 2, 3)\n",
    "\n",
    "# データセットの設定\n",
    "folder = ['Image']\n",
    "Class = ['Retry', 'Pass']\n",
    "image_size_x = 288\n",
    "image_size_y = 216\n",
    "T_value = 2.082677039\n",
    "ON_error = 0.07\n",
    "ON_line_upper = (1 + ON_error) * T_value\n",
    "ON_line_lower = (1 - ON_error) * T_value\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# 傾きデータを読み込む\n",
    "slope = np.loadtxt('ORR.csv')\n",
    "print(slope)\n",
    "\n",
    "# 各フォルダ内のファイルを処理\n",
    "for index, name in enumerate(folder):\n",
    "    dir = name\n",
    "    files = glob.glob(dir + \"\\*.jpg\")\n",
    "    print(files)\n",
    "\n",
    "    random_state = 11\n",
    "    fx_train, fx_test, fy_train, fy_test = train_test_split(files, slope, test_size=0.3, random_state=random_state)\n",
    "    fx_train, fx_val, fy_train, fy_val = train_test_split(fx_train, fy_train, test_size=0.3, random_state=random_state)\n",
    "\n",
    "    for i, file in enumerate(fx_train):\n",
    "        ori = Image.open(file).convert(\"L\")\n",
    "        ori = ori.resize((image_size_x, image_size_y))\n",
    "        ori = square(ori, 255)\n",
    "        ori = pil2opencv(ori)\n",
    "        hough(ori)\n",
    "        ori = opencv2pil(ori)\n",
    "\n",
    "        data = np.asarray(ori)\n",
    "        x_train.append(data)\n",
    "\n",
    "        if fy_train[i] < ON_line_lower:\n",
    "            y_train.append(0)\n",
    "        elif fy_train[i] > ON_line_upper:\n",
    "            y_train.append(0)\n",
    "        else:\n",
    "            y_train.append(1)\n",
    "\n",
    "        params = {'rotation_range': 180, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'vertical_flip': True, 'horizontal_flip': True, 'shear_range': 2}\n",
    "        datagen = image.ImageDataGenerator(**params)\n",
    "        x = data[np.newaxis]\n",
    "        x = x[:, :, :, np.newaxis]\n",
    "        gen = datagen.flow(x, batch_size=1)\n",
    "\n",
    "        for n in range(9):\n",
    "            batches = next(gen)\n",
    "            aug = np.squeeze(batches)\n",
    "            x_train.append(aug)\n",
    "            if fy_train[i] < ON_line_lower:\n",
    "                y_train.append(0)\n",
    "            elif fy_train[i] > ON_line_upper:\n",
    "                y_train.append(0)\n",
    "            else:\n",
    "                y_train.append(1)\n",
    "\n",
    "            if DEBUG:\n",
    "                gen_img = batches[0].astype(np.uint8)\n",
    "                plt.subplot(3, 3, n + 1)\n",
    "                plt.imshow(gen_img)\n",
    "                plt.axis('off')\n",
    "                plt.gray()\n",
    "                plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    for i, file in enumerate(fx_test):\n",
    "        ori = Image.open(file).convert(\"L\")\n",
    "        ori = ori.resize((image_size_x, image_size_y))\n",
    "        ori = square(ori, 255)\n",
    "        ori = pil2opencv(ori)\n",
    "        hough(ori)\n",
    "        ori = opencv2pil(ori)\n",
    "        data = np.asarray(ori)\n",
    "        x_test.append(data)\n",
    "\n",
    "        if fy_test[i] < ON_line_lower:\n",
    "            y_test.append(0)\n",
    "        elif fy_test[i] > ON_line_upper:\n",
    "            y_test.append(0)\n",
    "        else:\n",
    "            y_test.append(1)\n",
    "\n",
    "    for i, file in enumerate(fx_val):\n",
    "        ori = Image.open(file).convert(\"L\")\n",
    "        ori = ori.resize((image_size_x, image_size_y))\n",
    "        ori = square(ori, 255)\n",
    "        ori = pil2opencv(ori)\n",
    "        hough(ori)\n",
    "        ori = opencv2pil(ori)\n",
    "        data = np.asarray(ori)\n",
    "        x_val.append(data)\n",
    "\n",
    "        if fy_val[i] < ON_line_lower:\n",
    "            y_val.append(0)\n",
    "        elif fy_val[i] > ON_line_upper:\n",
    "            y_val.append(0)\n",
    "        else:\n",
    "            y_val.append(1)\n",
    "\n",
    "# データをnumpy配列に変換\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# データの型を変更し、正規化\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test / 255\n",
    "x_val = x_val.astype('float32')\n",
    "x_val = x_val / 255\n",
    "\n",
    "# ラベルをone-hotエンコード\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)\n",
    "y_val = to_categorical(y_val, 2)\n",
    "\n",
    "# データの形状を変更\n",
    "train_newarray = (x_train.shape[0], x_train.shape[1], x_train.shape[1], 1)\n",
    "x_train = np.reshape(x_train, train_newarray)\n",
    "\n",
    "test_newarray = (x_test.shape[0], x_test.shape[1], x_test.shape[1], 1)\n",
    "x_test = np.reshape(x_test, test_newarray)\n",
    "\n",
    "valid_newarray = (x_val.shape[0], x_val.shape[1], x_val.shape[1], 1)\n",
    "x_val = np.reshape(x_val, valid_newarray)\n",
    "\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"x_val\", x_val.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"y_test\", y_test.shape)\n",
    "print(\"y_val\", y_val.shape)\n",
    "\n",
    "# Adamオプティマイザの設定\n",
    "opt = optimizers.Adam(lr=0.05)\n",
    "\n",
    "# モデルを定義し、トレーニングを行う関数\n",
    "def model_train(x_train, y_train, x_val, y_val):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding=\"same\", input_shape=(x_train.shape[1], x_train.shape[2], 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[\"accuracy\"]\n",
    "                  )\n",
    "    print(\"x_train\", x_train.shape)\n",
    "    print(\"x_test\", x_test.shape)\n",
    "    print(\"x_val\", x_val.shape)\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    print(\"y_test\", y_test.shape)\n",
    "    print(\"y_val\", y_val.shape)\n",
    "\n",
    "    early_stopping = [EarlyStopping(patience=20, verbose=1)]\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=10, min_lr=0.0001)\n",
    "\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=32, epochs=200, shuffle=True, callbacks=[reduce_lr]) \n",
    "\n",
    "    model.save_weights('result/cnn_weights.h5')\n",
    "    model.save('result/cnn_model_weight.h5')\n",
    "\n",
    "    fig1 = plt.figure()\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    fig1.savefig(\"Accuracy.jpg\")\n",
    "\n",
    "    fig2 = plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show\n",
    "    fig2.savefig(\"Loss.jpg\")\n",
    "\n",
    "    fig3 = plt.figure()\n",
    "    plt.title(\"lr\")\n",
    "    plt.plot(range(len(history.history[\"lr\"])), history.history[\"lr\"])\n",
    "    plt.show()\n",
    "    fig3.savefig(\"lr.jpg\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# 精度を評価する関数\n",
    "def acc(y_label, y_pred):\n",
    "    return np.mean(np.abs(y_label - y_pred) < 0.1)\n",
    "\n",
    "# モデルを評価する関数\n",
    "def evaluate(model, x_test, y_test):\n",
    "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print(\"Test Loss: \", scores[0])\n",
    "    print(\"Test accuracy: \", scores[1])\n",
    "\n",
    "# データをシャッフル\n",
    "p = np.random.permutation(len(x_train))\n",
    "x_train, y_train = x_train[p], y_train[p]\n",
    "u = np.random.permutation(len(x_val))\n",
    "x_val, y_val = x_val[u], y_val[u]\n",
    "v = np.random.permutation(len(x_test))\n",
    "x_test, y_test = x_test[v], y_test[v]\n",
    "\n",
    "# モデルのトレーニング\n",
    "model = model_train(x_train, y_train, x_val, y_val)\n",
    "\n",
    "# モデルの評価\n",
    "evaluate(model, x_test, y_test)\n",
    "\n",
    "# 予測を行う\n",
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_val = model.predict(x_val)\n",
    "y_pred_test = model.predict(x_test)\n",
    "print(\"pred\", y_pred_test)\n",
    "print(\"val\", y_val)\n",
    "print(\"test\", y_test)\n",
    "\n",
    "print(\"train\")\n",
    "predicted = np.argmax(y_pred_train, 1)\n",
    "test = np.argmax(y_train, 1)\n",
    "print(classification_report(test, predicted, target_names=[\"Retry\", \"Pass\"]))\n",
    "print(\"val\")\n",
    "predicted = np.argmax(y_pred_val, 1)\n",
    "test = np.argmax(y_val, 1)\n",
    "print(classification_report(test, predicted, target_names=[\"Retry\", \"Pass\"]))\n",
    "print(\"test\")\n",
    "predicted = np.argmax(y_pred_test, 1)\n",
    "test = np.argmax(y_test, 1)\n",
    "print(classification_report(test, predicted, target_names=[\"Retry\", \"Pass\"]))\n",
    "\n",
    "# 結果をプロット\n",
    "plt.scatter(y_train, y_pred_train, s=20, c=\"blue\")\n",
    "plt.scatter(y_val, y_pred_val, s=20, c=\"green\")\n",
    "plt.scatter(y_test, y_pred_test, s=20, c=\"red\")\n",
    "plt.legend(['Train', 'Validation', 'Test'])\n",
    "plt.ylabel('Predict')\n",
    "plt.xlabel('Test')\n",
    "plt.xlim(-1, 2)\n",
    "plt.ylim(-1, 2)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (newenv)",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
